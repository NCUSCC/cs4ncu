import typer
import json
import re
from pathlib import Path
from ruamel.yaml import YAML, YAMLError
from rich.console import Console

# --- é…ç½® ---
ROOT_DIR = Path(__file__).parent.parent
DOCS_DIR = ROOT_DIR / "docs"
DATA_DIR = ROOT_DIR / "tools" / "data"
RAW_DB_PATH = DATA_DIR / "raw_database.json"
WEAVERIGNORE_PATH = ROOT_DIR / ".weaverignore"

# --- åˆå§‹åŒ– ---
app = typer.Typer()
yaml = YAML(typ="safe")
console = Console()


def load_ignore_patterns() -> list[str]:
    """åŠ è½½ .weaverignore æ–‡ä»¶ä¸­çš„å¿½ç•¥è§„åˆ™"""
    if not WEAVERIGNORE_PATH.exists():
        return []
    patterns = []
    with open(WEAVERIGNORE_PATH, "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if line and not line.startswith("#"):
                patterns.append(line)
    return patterns


def is_ignored(path: Path, patterns: list[str]) -> bool:
    """æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦åŒ¹é…ä»»ä½•å¿½ç•¥è§„åˆ™"""
    for pattern in patterns:
        if path.match(pattern):
            return True
    return False


def extract_frontmatter(content: str) -> (dict | None, str):
    """ä»æ–‡ä»¶å†…å®¹ä¸­åˆ†ç¦» frontmatter å’Œæ­£æ–‡"""
    fm_match = re.search(r"^---\s*\n(.*?)\n---\s*\n", content, re.DOTALL | re.MULTILINE)
    if not fm_match:
        return None, content
    frontmatter_str = fm_match.group(1)
    main_content = content[fm_match.end() :]
    try:
        return yaml.load(frontmatter_str), main_content
    except YAMLError:
        return None, content


# --- æ ¸å¿ƒä¼˜åŒ–ï¼šæ™ºèƒ½æ‘˜è¦æå–å‡½æ•° ---
def extract_intro_summary(content: str) -> str:
    """
    æ™ºèƒ½æå–æ‘˜è¦ï¼šè·³è¿‡æç¤ºæ¡†ï¼Œæ‰¾åˆ°ç¬¬ä¸€ä¸ªæœ‰æ•ˆæ®µè½ã€‚
    """
    # 1. æŒ‰è¡Œåˆ†å‰²æ­£æ–‡å†…å®¹
    lines = content.strip().split("\n")

    in_admonition_block = False
    first_paragraph = ""

    for line in lines:
        stripped_line = line.strip()

        # 2. è·³è¿‡æç¤ºæ¡† (admonition)
        if stripped_line.startswith(("!!!", "???")):
            in_admonition_block = True
            continue
        if in_admonition_block:
            # å¦‚æœåœ¨æç¤ºæ¡†å†…ï¼Œæ£€æŸ¥æ˜¯å¦å·²ç»ç»“æŸï¼ˆå³ï¼Œä¸å†æœ‰ç¼©è¿›ï¼‰
            if not line.startswith(("    ", "\t")):
                in_admonition_block = False
            else:
                continue

        # 3. è·³è¿‡æ ‡é¢˜ã€åˆ—è¡¨ã€åˆ†éš”ç¬¦ç­‰éæ®µè½å†…å®¹
        if not stripped_line or stripped_line.startswith(
            ("#", "*", "-", ">", "|", "`")
        ):
            continue

        # 4. æ‰¾åˆ°äº†ç¬¬ä¸€ä¸ªæœ‰æ•ˆæ®µè½ï¼
        # ç®€å•æ ¡éªŒé•¿åº¦ï¼Œè¿‡æ»¤æ‰å¤ªçŸ­çš„æ— æ„ä¹‰è¡Œ
        if len(stripped_line) > 20:  # é•¿åº¦é˜ˆå€¼ï¼Œå¯ä»¥è°ƒæ•´
            first_paragraph = stripped_line
            break  # æ‰¾åˆ°åç«‹å³é€€å‡ºå¾ªç¯

    return first_paragraph


def extract_headings(content: str) -> list[str]:
    """æå–æ‰€æœ‰çš„äºŒçº§å’Œä¸‰çº§æ ‡é¢˜"""
    headings = re.findall(r"^(##|###)\s+(.*)", content, re.MULTILINE)
    return [h[1].strip() for h in headings]


@app.command(help="æ„å»ºåŸå§‹æ•°æ®åº“ï¼Œæå–æ‰€æœ‰æ–‡ç« çš„å…ƒæ•°æ®å’Œæ‘˜è¦ã€‚")
def build_raw_db():
    """æ‰«æ docs/ ç›®å½•ï¼Œæå–æ¯ç¯‡æ–‡ç« çš„å…³é”®ä¿¡æ¯ï¼Œç”Ÿæˆ raw_database.jsonã€‚"""
    # (ä¸»å‡½æ•°é€»è¾‘ä¿æŒä¸å˜ï¼Œæ­¤å¤„çœç•¥ä»¥ä¿æŒç®€æ´)
    # ... ä½ å¯ä»¥ä»ä¸Šä¸€ä¸ªç‰ˆæœ¬å¤åˆ¶ build_raw_db å‡½æ•°çš„å®Œæ•´å†…å®¹ ...
    database = []

    console.log("[bold cyan]ğŸš€ å¼€å§‹æ‰«æé¡¹ç›®æ–‡ç« ...[/bold cyan]")

    ignore_patterns = load_ignore_patterns()
    if ignore_patterns:
        console.log(
            f"[dim] å·²åŠ è½½ {len(ignore_patterns)} æ¡å¿½ç•¥è§„åˆ™ä» .weaverignore[/dim]"
        )

    all_files = list(DOCS_DIR.rglob("*.md"))
    processed_files = 0

    with console.status("[bold green] æ­£åœ¨å¤„ç†æ–‡ä»¶...[/bold green]") as status:
        for md_file in all_files:
            relative_path = md_file.relative_to(ROOT_DIR)

            if is_ignored(relative_path, ignore_patterns):
                continue

            processed_files += 1
            status.update(f"æ­£åœ¨å¤„ç†ï¼š{relative_path}")

            content = md_file.read_text(encoding="utf-8")
            frontmatter, main_content = extract_frontmatter(content)

            if frontmatter is None or not isinstance(frontmatter, dict):
                console.log(f"[yellow] è·³è¿‡ï¼ˆæ ¼å¼ä¸è§„èŒƒï¼‰:[/yellow] {relative_path}")
                continue

            title = frontmatter.get("title", "æ— æ ‡é¢˜")
            tags = frontmatter.get("tags", [])
            intro_summary = extract_intro_summary(main_content)  # è°ƒç”¨æ–°çš„æ™ºèƒ½æå–å‡½æ•°
            headings = extract_headings(main_content)

            article_data = {
                "filepath": relative_path.as_posix(),
                "title": title,
                "tags": tags,
                "intro_summary": intro_summary,
                "headings": headings,
            }
            database.append(article_data)

    console.log(
        f"[bold green]âœ… æ–‡ä»¶æ‰«æå®Œæˆï¼å…±å‘ç° {len(all_files)} ä¸ªæ–‡ä»¶ï¼Œå®é™…å¤„ç† {processed_files} ä¸ªï¼ŒæˆåŠŸæå– {len(database)} ç¯‡æ–‡ç« ã€‚[/bold green]"
    )

    DATA_DIR.mkdir(exist_ok=True)

    with open(RAW_DB_PATH, "w", encoding="utf-8") as f:
        json.dump(database, f, indent=2, ensure_ascii=False)

    console.log(f"[bold blue]ğŸ’¾ åŸå§‹æ•°æ®åº“å·²æˆåŠŸä¿å­˜åˆ°ï¼š{RAW_DB_PATH}[/bold blue]")


if __name__ == "__main__":
    app()
